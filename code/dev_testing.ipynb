{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python setup.py sdist bdist_wheel\n",
    "\n",
    "twine upload --skip-existing dist/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ScraperFC as sfc\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraper = sfc.FBRef(driver=\"firefox\")\n",
    "# try:\n",
    "#     out = scraper.scrape_league_table(2021, 'EPL')\n",
    "# except:\n",
    "#     traceback.print_exc()\n",
    "# scraper.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - \n",
      "\n",
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 103.0.5060\n",
      "[WDM] - Get LATEST driver version for 103.0.5060\n",
      "[WDM] - Driver [C:\\Users\\Owner\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n",
      "c:\\Users\\Owner\\Documents\\GitHub\\ScraperFC\\code\\ScraperFC\\FBRef.py:965: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  match = pd.Series()\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_12480\\4062025093.py\", line 22, in <cell line: 19>\n",
      "    out = scraper.scrape_match(league=\"EPL\", year=packet[0], link=packet[1])\n",
      "  File \"c:\\Users\\Owner\\Documents\\GitHub\\ScraperFC\\code\\ScraperFC\\FBRef.py\", line 881, in scrape_match\n",
      "    df = pd.read_html(link)\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 311, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\", line 1113, in read_html\n",
      "    return _parse(\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\", line 919, in _parse\n",
      "    tables = p.parse_tables()\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\", line 239, in parse_tables\n",
      "    tables = self._parse_tables(self._build_doc(), self.match, self.attrs)\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\", line 758, in _build_doc\n",
      "    raise e\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\io\\html.py\", line 739, in _build_doc\n",
      "    with urlopen(self.io) as f:\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\", line 236, in urlopen\n",
      "    return urllib.request.urlopen(*args, **kwargs)\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\urllib\\request.py\", line 222, in urlopen\n",
      "    return opener.open(url, data, timeout)\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\urllib\\request.py\", line 531, in open\n",
      "    response = meth(req, response)\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\urllib\\request.py\", line 640, in http_response\n",
      "    response = self.parent.error(\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\urllib\\request.py\", line 569, in error\n",
      "    return self._call_chain(*args)\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\urllib\\request.py\", line 502, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"c:\\Users\\Owner\\anaconda3\\lib\\urllib\\request.py\", line 649, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 429: Too Many Requests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: Mon, 01 Aug 2022 02:29:24 GMT\n",
      "Content-Type: text/html; charset=UTF-8\n",
      "Transfer-Encoding: chunked\n",
      "Connection: close\n",
      "CF-Chl-Bypass: 1\n",
      "Permissions-Policy: accelerometer=(),autoplay=(),camera=(),clipboard-read=(),clipboard-write=(),fullscreen=(),geolocation=(),gyroscope=(),hid=(),interest-cohort=(),magnetometer=(),microphone=(),payment=(),publickey-credentials-get=(),screen-wake-lock=(),serial=(),sync-xhr=(),usb=()\n",
      "Cache-Control: private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0\n",
      "Expires: Thu, 01 Jan 1970 00:00:01 GMT\n",
      "X-Frame-Options: SAMEORIGIN\n",
      "Expect-CT: max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"\n",
      "Set-Cookie: __cf_bm=QfMS7NgnjmJmN6NcXWxtTRt7iWqyVj0N_0mk19U10AY-1659320964-0-AUCa7Z/HKjLi9upxGsIFFMiL2Pf8dOHgDBSWpNVyRxcCxBZHzkirV/PjMKVFGibVsUAlFvbiilm1SH+s+m/2ch0=; path=/; expires=Mon, 01-Aug-22 02:59:24 GMT; domain=.fbref.com; HttpOnly; Secure; SameSite=None\n",
      "Vary: Accept-Encoding\n",
      "Server: cloudflare\n",
      "CF-RAY: 733b255e7fba869e-ORD\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scraper = sfc.FBRef()\n",
    "\n",
    "packets = [\n",
    "    [\n",
    "        1993,\n",
    "        \"https://fbref.com/en/matches/2fc61b31/Liverpool-Tottenham-Hotspur-May-8-1993-Premier-League\"\n",
    "    ],\n",
    "    [\n",
    "        2017,\n",
    "        \"https://fbref.com/en/matches/78c3fc92/Hull-City-Leicester-City-August-13-2016-Premier-League\"\n",
    "    ],\n",
    "    [\n",
    "        2018,\n",
    "        \"https://fbref.com/en/matches/e3c3ddf0/Arsenal-Leicester-City-August-11-2017-Premier-League\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "out = 1\n",
    "while out != -1:\n",
    "    for packet in packets:\n",
    "        try:\n",
    "            out = scraper.scrape_match(league=\"EPL\", year=packet[0], link=packet[1])\n",
    "            if out is not int:\n",
    "                out = 1\n",
    "        except HTTPError as E:\n",
    "            traceback.print_exc()\n",
    "            print(E.headers)\n",
    "            out = -1\n",
    "        except IndexError:\n",
    "            pass\n",
    "scraper.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "585a938ec471c889bf0cce0aed741a99eaf47ca09c0fa8393793bc5bfe77ba11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
