{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "import ScraperFC as sfc\n",
    "import traceback\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load football-data.co.uk data\n",
    "odds_df = pd.DataFrame()\n",
    "filenames = ['2019-20.csv', '2020-21.csv', '2021-22.csv']\n",
    "for filename in filenames:\n",
    "    t = pd.read_csv(filename)\n",
    "    odds_df = pd.concat([odds_df, t], axis=0, ignore_index=True)\n",
    "\n",
    "# Load fivethirtyeight data\n",
    "scraper = sfc.FiveThirtyEight()\n",
    "try:\n",
    "    fte_df = pd.DataFrame()\n",
    "    years = range(2020,2023)\n",
    "    for year in years:\n",
    "        t = scraper.scrape_matches(year, 'EPL')\n",
    "        fte_df = pd.concat([fte_df, t], axis=0, ignore_index=True)\n",
    "    clear_output()\n",
    "except:\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    scraper.close()\n",
    "\n",
    "# Convert date columns to datetime objects\n",
    "fte_df['date'] = pd.to_datetime(fte_df['date'], format='%Y-%m-%d')\n",
    "odds_df['Date'] = pd.to_datetime(odds_df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# map fivethirtyeight team names to football-data.co.uk team names\n",
    "team_mappings = { \n",
    "    'AFC Bournemouth': 'Bournemouth', \n",
    "    'Brighton and Hove Albion': 'Brighton',\n",
    "    'Cardiff City': 'Cardiff', \n",
    "    'Huddersfield Town': 'Huddersfield', \n",
    "    'Leeds United': 'Leeds', \n",
    "    'Leicester City': 'Leicester', \n",
    "    'Manchester City': 'Man City', \n",
    "    'Manchester United': 'Man United', \n",
    "    'Norwich City': 'Norwich',\n",
    "    'Stoke City': 'Stoke', \n",
    "    'Swansea City': 'Swansea', \n",
    "    'Tottenham Hotspur': 'Tottenham',\n",
    "    'West Bromwich Albion': 'West Brom', \n",
    "    'West Ham United': 'West Ham', \n",
    "    'Wolverhampton': 'Wolves',\n",
    "}\n",
    "fte_df = fte_df.replace({'team1': team_mappings, 'team2': team_mappings})\n",
    "\n",
    "# Merge dataframes\n",
    "df = pd.merge(fte_df, odds_df, left_on=['date','team1','team2'], right_on=['Date','HomeTeam','AwayTeam'])\n",
    "\n",
    "fte_cols = [\n",
    "    'prob1', 'prob2', 'probtie', # FTE probas\n",
    "    'proj_score1', 'proj_score2', # FTE projected scores\n",
    "    'spi1', 'spi2', # FTE SPI index\n",
    "    'importance1', 'importance2', # FTE match importance values\n",
    "]\n",
    "odds_cols = [\n",
    "    # Outcomes odds\n",
    "    'B365H', 'B365D', 'B365A', # Bet365 odds\n",
    "    # 'BSH', 'BSD', 'BSA', # Blue Square odds\n",
    "    'BWH', 'BWD', 'BWA', # Bet&Win odds\n",
    "    # 'GBH', 'GBD', 'GBA', # Gamebookers odds\n",
    "    'IWH', 'IWD', 'IWA', # Interwetten odds\n",
    "    # 'LBH', 'LBD', 'LBA', # Ladbrokes odds\n",
    "    # 'PSH and PH', 'PSD and PD', 'PSA and PA', # Pinnacle odds\n",
    "    # 'SOH', 'SOD', 'SOA', # Sporting Odds odds\n",
    "    # 'SBH', 'SBD', 'SBA', # Sportingbet odds\n",
    "    # 'SJH', 'SJD', 'SJA', # Stan James odds\n",
    "    # 'SYH', 'SYD', 'SYA', # Stanleybet odds\n",
    "    'VCH', 'VCD', 'VCA', # VC Bet odds\n",
    "    'WHH', 'WHD', 'WHA', # William Hill odds\n",
    "    # 'Bb1X2', # Number of BetBrain bookmakers used to calculate match odds averages and maximums\n",
    "    # 'BbMxH', 'BbMxD', 'BbMxA', # Betbrain maximum odds\n",
    "    # 'BbAvH', 'BbAvD', 'BbAvA', # Betbrain average odds\n",
    "    'MaxH', 'MaxD', 'MaxA',# Market maximum odds\n",
    "    'AvgH', 'AvgD', 'AvgA', # Market average odds\n",
    "    # Total goals odds\n",
    "    # 'BbOU', # Number of BetBrain bookmakers used to calculate over/under 2.5 goals (total goals) averages and maximums\n",
    "    # 'BbMx>2.5', 'BbMx<2.5', # Betbrain maximum over/under 2.5 goals\n",
    "    # 'BbAv>2.5', 'BbAv<2.5', # Betbrain average over/under 2.5 goals\n",
    "    # 'GB>2.5', 'GB<2.5', # Gamebookers over/under 2.5 goals\n",
    "    'B365>2.5', 'B365<2.5', # Bet365 over/under 2.5 goals\n",
    "    'P>2.5', 'P<2.5', # Pinnacle over/under 2.5 goals\n",
    "    'Max>2.5', 'Max<2.5', # Market maximum over/under 2.5 goals\n",
    "    'Avg>2.5', 'Avg<2.5', # Market average over/under 2.5 goals\n",
    "    # Asian handicap odds\n",
    "    # 'BbAH', # Number of BetBrain bookmakers used to Asian handicap averages and maximums\n",
    "    # 'BbAHh', # Betbrain size of handicap (home team)\n",
    "    'AHh', # Market size of handicap (home team) (since 2019/2020)\n",
    "    # 'BbMxAHH', 'BbMxAHA', # Betbrain maximum Asian handicap team odds\n",
    "    # 'BbAvAHH', 'BbAvAHA', # Betbrain average Asian handicap team odds\n",
    "    # 'GBAHH', 'GBAHA', # Gamebookers Asian handicap home team odds\n",
    "    # 'GBAH', # Gamebookers size of handicap (home team)\n",
    "    # 'LBAHH', 'LBAHA ', # Ladbrokes Asian handicap team odds\n",
    "    # 'LBAH', # Ladbrokes size of handicap (home team)\n",
    "    'B365AHH', 'B365AHA', # Bet365 Asian handicap team odds\n",
    "    # 'B365AH', # Bet365 size of handicap (home team)\n",
    "    'PAHH', 'PAHA', # Pinnacle Asian handicap team odds\n",
    "    'MaxAHH', 'MaxAHA', # Market maximum Asian handicap team odds\n",
    "    'AvgAHH', 'AvgAHA', # Market average Asian handicap team odds\n",
    "]\n",
    "input_cols = fte_cols + odds_cols\n",
    "\n",
    "# Add hits columns for actual outcomes\n",
    "df['home win'] = df['score1'] > df['score2']\n",
    "df['away win'] = df['score2'] > df['score1']\n",
    "df['draw'] = df['score1'] == df['score2']\n",
    "df['over 2.5 goals'] = (df['score1']+df['score2']) > 2.5\n",
    "df['under 2.5 goals'] = (df['score1']+df['score2']) < 2.5\n",
    "label_cols = ['home win', 'away win', 'draw', 'over 2.5 goals', 'under 2.5 goals']\n",
    "df[label_cols] = df[label_cols].astype(float)\n",
    "\n",
    "# Remove '<' and '>' from columns names\n",
    "for i in range(len(input_cols)):\n",
    "    if '<' in input_cols[i]:\n",
    "        input_cols[i] = input_cols[i].replace('<','under')\n",
    "    elif '>' in input_cols[i]:\n",
    "        input_cols[i] = input_cols[i].replace('>','over')\n",
    "df.columns = df.columns.str.replace('<','under')\n",
    "df.columns = df.columns.str.replace('>','over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-validation-test split\n",
    "random_state = 18\n",
    "train, valid, test = 0.7, 0.15, 0.15\n",
    "assert (train + valid + test) == 1\n",
    "train_valid_df, test_df = train_test_split(df, test_size=test, random_state=random_state)\n",
    "train_df, valid_df = train_test_split(train_valid_df, test_size=valid/(train+valid), random_state=random_state)\n",
    "\n",
    "# Train\n",
    "X = train_df[input_cols]\n",
    "y = train_df[label_cols]\n",
    "xgb = XGBRegressor(tree_method='gpu_hist')\n",
    "xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312 bets placed.\n",
      "149 bets won.\n",
      "$-35.72 won.\n"
     ]
    }
   ],
   "source": [
    "bet_thresh = 0.5\n",
    "\n",
    "yhat = xgb.predict(valid_df[input_cols])\n",
    "yhat_df = pd.DataFrame(data=yhat, columns=label_cols)\n",
    "\n",
    "# Flags for bets placed\n",
    "bets = (yhat_df > bet_thresh).astype(float).reset_index(drop=True)\n",
    "# Flags for outcomes occurring\n",
    "outcomes = valid_df[label_cols].reset_index(drop=True)\n",
    "# AND of bets placed and outcomes occurred\n",
    "wins = bets * outcomes\n",
    "\n",
    "# Compute payouts\n",
    "avg_odds = valid_df[['AvgH', 'AvgA', 'AvgD', 'Avgover2.5', 'Avgunder2.5']]\n",
    "payouts = np.multiply(wins, avg_odds.values) - bets\n",
    "payouts = np.round(payouts, 2)\n",
    "\n",
    "print(f'{int(bets.values.sum())} bets placed.')\n",
    "print(f'{int(wins.values.sum())} bets won.')\n",
    "print(f'${np.sum(payouts.values)} won.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc273e64c6c48e9881aab795f8d0e622d86c0ebe91aa99d17d2821087e5340fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
