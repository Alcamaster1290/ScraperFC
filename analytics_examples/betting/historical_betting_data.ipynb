{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo\n",
    "* Scrape home and away team names in scrape_match()\n",
    "* Gather data from a season and build training pipeline\n",
    "* Train on limited data and evaluate\n",
    "* Gather and train on more data if initial train is promising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "sys.path.append('../..')\n",
    "import ScraperFC as sfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================================================================\n",
    "def get_match_links(year=None):\n",
    "    \"\"\"\n",
    "    year=None for current season\n",
    "    \"\"\"\n",
    "    if not year:\n",
    "        url = 'https://www.oddsportal.com/soccer/england/premier-league/results/'\n",
    "    else:\n",
    "        url = f'https://www.oddsportal.com/soccer/england/premier-league-{year-1}-{year}/results/'\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    done = False\n",
    "    match_links = list()\n",
    "    while not done:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser') # update soup\n",
    "        links = soup.find_all('a',{'class': re.compile('flex-col')}, href=True)\n",
    "        links = ['https://oddsportal.com'+el['href'] for el in links if 'premier-league' in el['href']]\n",
    "        match_links += links\n",
    "\n",
    "        next_button = [el for el in soup.find_all('p') if 'next'==el.text.lower()]\n",
    "        if len(next_button) == 0:\n",
    "            done = True\n",
    "        else:\n",
    "            next_button_xpath = sfc.xpath_soup(next_button[0])\n",
    "            next_button = driver.find_element(By.XPATH, next_button_xpath)\n",
    "            driver.execute_script('arguments[0].scrollIntoView()', next_button)\n",
    "            driver.execute_script('arguments[0].click()', next_button)\n",
    "            # Wait for next or prev buttons to load\n",
    "            loaded = False\n",
    "            while not loaded:\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser') # update soup\n",
    "                next_button = [el for el in soup.find_all('p') if 'next'==el.text.lower()]\n",
    "                prev_button = [el for el in soup.find_all('p') if 'prev'==el.text.lower()]\n",
    "                if next_button or prev_button:\n",
    "                    loaded = True\n",
    "\n",
    "    match_links = list(set(match_links)) # remove any repeats links, if they exist for some reason\n",
    "\n",
    "    return match_links\n",
    "\n",
    "#=======================================================================================================================\n",
    "def scrape_match(url):\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Date\n",
    "    date = soup.find('div', {'class': re.compile('start-time')}).parent.text.replace('\\xa0', ' ')\n",
    "    date = datetime.datetime.strptime(date, '%A, %d %b %Y, %H:%M')\n",
    "    # Team names\n",
    "    imgs  = soup.find_all('img')\n",
    "    teams = [\n",
    "        img.parent.find('p').text for img in imgs \n",
    "        if img['src'] and 'team-logo' in img['src']\n",
    "    ]\n",
    "    team1 = teams[0]\n",
    "    team2 = teams[1]\n",
    "    # Goals and result\n",
    "    final_result = [\n",
    "        el.text for el in soup.find_all('strong') \n",
    "        if re.search('(?=.*Final)(?=.*result)', el.parent.text)\n",
    "    ][0]\n",
    "    goals1 = int(final_result.split(':')[0])\n",
    "    goals2 = int(final_result.split(':')[1])\n",
    "    result = '1' if goals1>goals2 else ('X' if goals1==goals2 else '2')\n",
    "\n",
    "    match_df = pd.Series(dtype=object)\n",
    "    match_df['Date'] = date\n",
    "    match_df['Team1'] = team1\n",
    "    match_df['Team2'] = team2\n",
    "    match_df['Result'] = result\n",
    "    match_df['Goals1'] = goals1\n",
    "    match_df['Goals2'] = goals2\n",
    "    match_df['Total goals'] = goals1 + goals2\n",
    "\n",
    "    # Scrape odds\n",
    "    match1X2odds_df = get_1X2odds_from_match(url)\n",
    "    matchOUodds_df = get_OUodds_from_match(url)\n",
    "\n",
    "    match_df = match_df.to_frame().T\n",
    "    match_df = pd.concat([match_df, match1X2odds_df, matchOUodds_df], axis=1)\n",
    "\n",
    "    return match_df\n",
    "\n",
    "#=======================================================================================================================\n",
    "def get_1X2odds_from_match(url):\n",
    "    if '#1X2' not in url:\n",
    "        url += '#1X2'\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # # Hide inactive odds\n",
    "    # hide_inactive_checkbox = [el for el in soup.find_all('label') if 'Hide inactive odds' in el.text][0].parent.find('input', {'type': 'checkbox'})\n",
    "    # hide_inactive_checkbox = driver.find_element(By.XPATH, sfc.xpath_soup(hide_inactive_checkbox))\n",
    "    # driver.execute_script('arguments[0].scrollIntoView', hide_inactive_checkbox)\n",
    "    # driver.execute_script('arguments[0].click()', hide_inactive_checkbox)\n",
    "    # time.sleep(0.5)\n",
    "    # soup = BeautifulSoup(driver.page_source, 'html.parser') # update soup\n",
    "\n",
    "    odds_df = pd.Series(dtype=object)\n",
    "\n",
    "    odds_table = soup.find_all('div', {'class':'flex flex-col'})[1]\n",
    "    rows = odds_table.find_all('div', {'class':re.compile('flex text-xs')})\n",
    "    for row in rows:\n",
    "        bookie_info = row.find_all('a')\n",
    "        odds = row.find_all('div', recursive=False)\n",
    "\n",
    "        # Skip some rows\n",
    "        skip_conds = (\n",
    "            (len(odds) <= 1) # Odds not formatted right\n",
    "            or ('coupon' in odds[0].text.lower()) # Coupon row\n",
    "            or odds[4].text == ' - ' # Odds are crossed out (payout column is a dash)\n",
    "        )\n",
    "        if skip_conds:\n",
    "            continue\n",
    "\n",
    "        # Odds 0 is the bookie info div\n",
    "        odds1 = float(odds[1].text)\n",
    "        oddsX = float(odds[2].text)\n",
    "        odds2 = float(odds[3].text)\n",
    "        payout_perc = float(odds[4].text.replace('%',''))\n",
    "\n",
    "        if (len(bookie_info) <= 1):\n",
    "            # Average and max odds rows\n",
    "            agg_type = odds[0].text\n",
    "            odds_df[f'{agg_type} 1'] = odds1\n",
    "            odds_df[f'{agg_type} X'] = oddsX\n",
    "            odds_df[f'{agg_type} 2'] = odds2\n",
    "            odds_df[f'{agg_type} po %'] = payout_perc\n",
    "        else:\n",
    "            # This is a row with odds from bookie\n",
    "            bookie_url = bookie_info[0]['href']\n",
    "            bookie_name = bookie_info[1].text\n",
    "            # bookie info 2 is the info button (link to oddsportal page for bookie)\n",
    "            # bookie info 3 is whether the bookie is running a bonus or not\n",
    "            odds_df[f'{bookie_name} 1'] = odds1\n",
    "            odds_df[f'{bookie_name} X'] = oddsX\n",
    "            odds_df[f'{bookie_name} 2'] = odds2\n",
    "            odds_df[f'{bookie_name} po %'] = payout_perc\n",
    "\n",
    "    odds_df = odds_df.to_frame().T\n",
    "\n",
    "    return odds_df\n",
    "\n",
    "#=======================================================================================================================\n",
    "def get_OUodds_from_match(url):\n",
    "    if '#over-under' not in url:\n",
    "        url += '#over-under'\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for handicaps table to load\n",
    "    loaded = False\n",
    "    while not loaded:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser') # update soup\n",
    "        handicaps_table = soup.find_all('div', {'class':'min-md:px-[10px]'})\n",
    "        if len(handicaps_table) >= 2:\n",
    "            loaded = True\n",
    "\n",
    "    # # Hide inactive odds\n",
    "    # hide_inactive_checkbox = [el for el in soup.find_all('label') if 'Hide inactive odds' in el.text][0].parent.find('input', {'type': 'checkbox'})\n",
    "    # hide_inactive_checkbox = driver.find_element(By.XPATH, sfc.xpath_soup(hide_inactive_checkbox))\n",
    "    # driver.execute_script('arguments[0].scrollIntoView', hide_inactive_checkbox)\n",
    "    # driver.execute_script('arguments[0].click()', hide_inactive_checkbox)\n",
    "    # time.sleep(0.5)\n",
    "    # soup = BeautifulSoup(driver.page_source, 'html.parser') # update soup\n",
    "    \n",
    "    # soup = BeautifulSoup(driver.page_source, 'html.parser') # update soup\n",
    "    # handicaps_table = soup.find_all('div', {'class':'min-md:px-[10px]'})[1]\n",
    "    handicaps_table = handicaps_table[1]\n",
    "    handicap_rows = handicaps_table.find_all('div', {'class':'relative flex flex-col'}, recursive=False)\n",
    "\n",
    "    odds_df = pd.Series(dtype=object)\n",
    "    for handicap_row in handicap_rows:\n",
    "        handicap = handicap_row.find('p').text.replace('Over/Under','').strip()\n",
    "\n",
    "        # Click on handicap row to expand odds\n",
    "        row_button = driver.find_element(By.XPATH, sfc.xpath_soup(handicap_row.find('div')))\n",
    "        driver.execute_script('arguments[0].scrollIntoView()', row_button)\n",
    "        driver.execute_script('arguments[0].click()', row_button)\n",
    "\n",
    "        # Wait for odds table to load\n",
    "        loaded = False\n",
    "        while not loaded:\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser') # update soup\n",
    "            odds_table = soup.find_all('div', {'class': 'flex flex-col'})\n",
    "            if len(odds_table) > 0:\n",
    "                loaded = True\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser') # update soup\n",
    "        odds_table = soup.find_all('div', {'class': 'flex flex-col'})[1]\n",
    "        odds_rows = odds_table.find_all('div', {'class':re.compile('flex text-xs')})\n",
    "        for odds_row in odds_rows:\n",
    "            bookie_info = odds_row.find_all('a')\n",
    "            odds = odds_row.find_all('div', recursive=False)\n",
    "\n",
    "            # Skip some rows\n",
    "            skip_conds = (\n",
    "                (len(odds) <= 1) # Odds not formatted right\n",
    "                or ('coupon' in odds[0].text.lower()) # Coupon row\n",
    "                or np.any([el.text==' - ' for el in odds]) # Odds are crossed out (payout column is a dash)\n",
    "            )\n",
    "            if skip_conds:\n",
    "                continue\n",
    "\n",
    "            if (len(bookie_info) <= 1):\n",
    "                # Average and max odds rows\n",
    "                agg_type = odds[0].text\n",
    "                over = None if odds[1].text=='-' else float(odds[1].text)\n",
    "                under = None if odds[2].text=='-' else float(odds[2].text)\n",
    "                payout_perc = float(odds[3].text.replace('%',''))\n",
    "                odds_df[f'{agg_type} {handicap} over'] = over\n",
    "                odds_df[f'{agg_type} {handicap} under'] = under\n",
    "                odds_df[f'{agg_type} {handicap} po %'] = payout_perc\n",
    "            else:\n",
    "                bookie_url = bookie_info[0]['href']\n",
    "                bookie_name = bookie_info[1].text\n",
    "                over = None if odds[2].text=='-' else float(odds[2].text)\n",
    "                under = None if odds[3].text=='-' else float(odds[3].text)\n",
    "                payout_perc = float(odds[4].text.replace('%',''))\n",
    "                odds_df[f'{bookie_name} {handicap} over'] = over\n",
    "                odds_df[f'{bookie_name} {handicap} under'] = under\n",
    "                odds_df[f'{bookie_name} {handicap} po %'] = payout_perc\n",
    "\n",
    "    odds_df = odds_df.to_frame().T\n",
    "\n",
    "    return odds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "prefs = {'profile.managed_default_content_settings.images': 2} # don't load images\n",
    "options.add_experimental_option('prefs', prefs)\n",
    "driver = webdriver.Chrome(\n",
    "    service=ChromeService(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [2021, 2020, 2019, 2018]:\n",
    "    odds_df = pd.DataFrame()\n",
    "    match_links = get_match_links(year)\n",
    "    for link in tqdm(match_links, desc=f'Scraping {year} EPL match odds'):\n",
    "        match_df = scrape_match(link)\n",
    "        odds_df = pd.concat([odds_df, match_df], axis=0, ignore_index=True)\n",
    "    odds_df.to_pickle(f'epl_{year}_odds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc273e64c6c48e9881aab795f8d0e622d86c0ebe91aa99d17d2821087e5340fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
